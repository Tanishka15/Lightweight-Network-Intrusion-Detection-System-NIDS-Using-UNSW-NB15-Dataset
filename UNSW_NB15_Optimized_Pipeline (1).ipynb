{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "50f6356c",
      "metadata": {
        "id": "50f6356c"
      },
      "source": [
        "# Lightweight UNSW-NB15 ML Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdaEcL7BfFZ0",
        "outputId": "4b439b07-7ace-4686-a023-c2fb4016ed65"
      },
      "id": "YdaEcL7BfFZ0",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['proto', 'state', 'dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss',\n",
            "       'dloss', 'service', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin',\n",
            "       'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len',\n",
            "       'Sjit', 'Djit', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat',\n",
            "       'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login',\n",
            "       'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm',\n",
            "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'label'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNSW-NB15 Pipeline with Correct Column Headers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# 1. Load data with proper column names (standard UNSW-NB15 columns)\n",
        "correct_columns = [\n",
        "    'srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'dur', 'sbytes',\n",
        "    'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload',\n",
        "    'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz',\n",
        "    'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime', 'Sintpkt',\n",
        "    'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl',\n",
        "    'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst',\n",
        "    'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm',\n",
        "    'ct_dst_src_ltm', 'attack_cat', 'label'\n",
        "]\n",
        "\n",
        "try:\n",
        "    # Load with correct column names (skip header if it exists)\n",
        "    df1 = pd.read_csv('/content/drive/MyDrive/UNSW-NB15_1.csv', names=correct_columns, header=None)\n",
        "    df2 = pd.read_csv('/content/drive/MyDrive/UNSW-NB15_2.csv', names=correct_columns, header=None)\n",
        "\n",
        "    df = pd.concat([df1, df2], ignore_index=True)\n",
        "    df = df.sample(n=5000, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    print(\"Data loaded successfully with proper column names\")\n",
        "    print(\"\\nFirst 3 rows:\")\n",
        "    print(df.head(3))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    raise\n",
        "\n",
        "# 2. Verify we have the label column\n",
        "if 'label' not in df.columns:\n",
        "    raise ValueError(\"Label column not found after assigning proper column names\")\n",
        "\n",
        "# 3. Data Preprocessing\n",
        "# Drop network identifiers and timestamps\n",
        "cols_to_drop = ['srcip', 'sport', 'dstip', 'dsport', 'Stime', 'Ltime']\n",
        "df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
        "\n",
        "# Separate features and label\n",
        "y = df['label']\n",
        "X = df.drop(columns=['label'])\n",
        "\n",
        "# Convert label to binary (0=normal, 1=attack)\n",
        "y = y.apply(lambda x: 0 if x == 0 else 1)  # Assuming 0 is normal, others are attacks\n",
        "\n",
        "# Handle categorical features\n",
        "cat_cols = X.select_dtypes(include=['object']).columns\n",
        "for col in cat_cols:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "\n",
        "# Fill missing values\n",
        "X.fillna(0, inplace=True)\n",
        "\n",
        "# 4. Feature Processing\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "selector = SelectKBest(mutual_info_classif, k=20)\n",
        "X_selected = selector.fit_transform(X_scaled, y)\n",
        "\n",
        "# 5. Model Training\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\nModel Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heSC0G3Xi4R2",
        "outputId": "beb71f4c-12fa-4250-fe7a-3ca81f6cfa66"
      },
      "id": "heSC0G3Xi4R2",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-c5a00d699e5c>:24: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df1 = pd.read_csv('/content/drive/MyDrive/UNSW-NB15_1.csv', names=correct_columns, header=None)\n",
            "<ipython-input-25-c5a00d699e5c>:25: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df2 = pd.read_csv('/content/drive/MyDrive/UNSW-NB15_2.csv', names=correct_columns, header=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully with proper column names\n",
            "\n",
            "First 3 rows:\n",
            "        srcip  sport          dstip dsport proto state       dur  sbytes  \\\n",
            "0  59.166.0.0   6620  149.171.126.8     21   tcp   FIN  1.455835    2934   \n",
            "1  59.166.0.6  43350  149.171.126.4     21   tcp   FIN  1.686769    2934   \n",
            "2  59.166.0.8  43404  149.171.126.5     25   tcp   FIN  0.025943   37428   \n",
            "\n",
            "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
            "0    3742    31  ...           0           1           1          5   \n",
            "1    3742    31  ...           1           1           1          5   \n",
            "2    3172    31  ...           0          14           9          5   \n",
            "\n",
            "   ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  attack_cat  \\\n",
            "0           9                 1                 1               3         NaN   \n",
            "1           3                 1                 1               3         NaN   \n",
            "2           3                 1                 1               2         NaN   \n",
            "\n",
            "   label  \n",
            "0      0  \n",
            "1      0  \n",
            "2      0  \n",
            "\n",
            "[3 rows x 49 columns]\n",
            "\n",
            "Model Performance:\n",
            "Accuracy: 1.0000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[945   0]\n",
            " [  0  55]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       945\n",
            "           1       1.00      1.00      1.00        55\n",
            "\n",
            "    accuracy                           1.00      1000\n",
            "   macro avg       1.00      1.00      1.00      1000\n",
            "weighted avg       1.00      1.00      1.00      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust UNSW-NB15 Pipeline with Column Validation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# Data Validation Checks\n",
        "print(\"\\n=== Data Validation ===\")\n",
        "print(f\"Total samples: {len(df)}\")\n",
        "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
        "print(\"\\nCurrent columns in DataFrame:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Identify which columns actually exist in the DataFrame\n",
        "columns_to_drop = ['label']  # We always keep this as our target\n",
        "optional_columns_to_drop = ['attack_cat', 'srcip', 'dstip', 'sport', 'dsport', 'Stime', 'Ltime']\n",
        "existing_columns_to_drop = [col for col in optional_columns_to_drop if col in df.columns]\n",
        "\n",
        "print(\"\\nColumns that will be dropped:\")\n",
        "print(existing_columns_to_drop)\n",
        "\n",
        "# Enhanced Preprocessing\n",
        "X = df.drop(columns=['label'] + existing_columns_to_drop)\n",
        "y = np.where(df['label'] == 0, 0, 1)  # Binary classification\n",
        "\n",
        "# Convert categoricals (more robust method)\n",
        "cat_cols = X.select_dtypes(include=['object']).columns\n",
        "print(f\"\\nCategorical columns to encode: {list(cat_cols)}\")\n",
        "\n",
        "for col in cat_cols:\n",
        "    X[col] = X[col].astype(str).replace('nan', 'unknown')\n",
        "    X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "# Handle numerical features\n",
        "num_cols = X.select_dtypes(include=np.number).columns\n",
        "X[num_cols] = X[num_cols].fillna(X[num_cols].median())\n",
        "\n",
        "# Create balanced train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Build pipeline with SMOTE for class balancing\n",
        "pipeline = ImbPipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('feature_selection', SelectKBest(mutual_info_classif, k=15)),\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=8,\n",
        "        class_weight='balanced_subsample',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Cross-validation\n",
        "print(\"\\n=== Cross-Validation ===\")\n",
        "cv_scores = cross_val_score(pipeline, X_train, y_train,\n",
        "                          cv=5, scoring='roc_auc')\n",
        "print(f\"Mean ROC-AUC: {np.mean(cv_scores):.3f} (±{np.std(cv_scores):.3f})\")\n",
        "\n",
        "# Final training and evaluation\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\n=== Final Evaluation ===\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Feature Importance Analysis\n",
        "if hasattr(pipeline.named_steps['classifier'], 'feature_importances_'):\n",
        "    print(\"\\n=== Top Important Features ===\")\n",
        "    selected_features = X.columns[pipeline.named_steps['feature_selection'].get_support()]\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': selected_features,\n",
        "        'importance': pipeline.named_steps['classifier'].feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    print(feature_importance.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcjNqMjIke5Y",
        "outputId": "4a7983c5-32f6-4be0-ca6f-9555fdf65933"
      },
      "id": "EcjNqMjIke5Y",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Data Validation ===\n",
            "Total samples: 5000\n",
            "Duplicate rows: 13\n",
            "\n",
            "Current columns in DataFrame:\n",
            "['proto', 'state', 'dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat', 'label']\n",
            "\n",
            "Columns that will be dropped:\n",
            "['attack_cat']\n",
            "\n",
            "Categorical columns to encode: ['proto', 'state', 'service', 'ct_ftp_cmd']\n",
            "\n",
            "=== Cross-Validation ===\n",
            "Mean ROC-AUC: 0.999 (±0.001)\n",
            "\n",
            "=== Final Evaluation ===\n",
            "Accuracy: 0.9927\n",
            "ROC-AUC: 0.9986\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1408   10]\n",
            " [   1   81]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00      1418\n",
            "           1       0.89      0.99      0.94        82\n",
            "\n",
            "    accuracy                           0.99      1500\n",
            "   macro avg       0.94      0.99      0.97      1500\n",
            "weighted avg       0.99      0.99      0.99      1500\n",
            "\n",
            "\n",
            "=== Top Important Features ===\n",
            "         feature  importance\n",
            "14  ct_state_ttl    0.263336\n",
            "4           sttl    0.250780\n",
            "7          Dload    0.107921\n",
            "10       dmeansz    0.073969\n",
            "8          Dpkts    0.058338\n",
            "5           dttl    0.045016\n",
            "3         dbytes    0.033769\n",
            "12        tcprtt    0.029145\n",
            "1            dur    0.028760\n",
            "0          state    0.028533\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}